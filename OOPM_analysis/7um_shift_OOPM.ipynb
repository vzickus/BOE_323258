{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive\n",
    "import glob, sys, os\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from scipy.misc import imread\n",
    "import skimage\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage.util import random_noise, img_as_uint\n",
    "from loading_and_piv_funcs_new import *\n",
    "import tifffile as tiff\n",
    "import os, sys\n",
    "from loading_and_piv_funcs_new import *\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 massive corr result:  2990 24.1497502614 -0.149750261411\n",
      "2 massive corr result:  2980 24.1438653828 -0.14386538282\n",
      "3 massive corr result:  2970 24.1286421262 -0.12864212616\n",
      "4 massive corr result:  2960 24.046593318 -0.0465933179619\n",
      "1 massive corr result:  2991 24.1681027785 -0.168102778508\n",
      "2 massive corr result:  2981 24.1585436564 -0.158543656442\n",
      "3 massive corr result:  2971 24.2234798504 -0.223479850379\n",
      "4 massive corr result:  2961 24.2573250137 -0.257325013749\n",
      "1 massive corr result:  2991 24.0762742573 -0.0762742573435\n",
      "2 massive corr result:  2981 24.1789388658 -0.178938865769\n",
      "3 massive corr result:  2971 24.3236696979 -0.323669697877\n",
      "4 massive corr result:  2961 24.1395454715 -0.13954547152\n",
      "1 massive corr result:  2991 23.825041305 0.174958694969\n",
      "2 massive corr result:  2981 23.9631116867 0.0368883133279\n",
      "3 massive corr result:  2971 24.1565834821 -0.156583482086\n",
      "4 massive corr result:  2961 24.3219947312 -0.321994731249\n",
      "1 massive corr result:  2990 24.0769828372 -0.0769828372\n",
      "2 massive corr result:  2980 24.0806020962 -0.0806020962283\n",
      "3 massive corr result:  2970 24.0344184361 -0.0344184361398\n",
      "4 massive corr result:  2960 24.0709942647 -0.0709942646955\n",
      "1 massive corr result:  2990 24.0634680557 -0.0634680557264\n",
      "2 massive corr result:  2980 24.1670871721 -0.167087172091\n",
      "3 massive corr result:  2970 24.2609857642 -0.260985764165\n",
      "4 massive corr result:  2960 24.2564912203 -0.256491220297\n",
      "1 massive corr result:  2991 24.084633867 -0.0846338669986\n",
      "2 massive corr result:  2981 24.1014212526 -0.101421252563\n",
      "3 massive corr result:  2971 24.237982944 -0.237982944013\n",
      "4 massive corr result:  2961 24.2859725655 -0.285972565465\n",
      "1 massive corr result:  2991 24.0275771499 -0.0275771499476\n",
      "2 massive corr result:  2981 24.131266935 -0.131266934959\n",
      "3 massive corr result:  2971 24.3865909402 -0.386590940238\n",
      "4 massive corr result:  2961 24.1296482839 -0.129648283931\n",
      "1 massive corr result:  2991 23.996815378 0.00318462197396\n",
      "2 massive corr result:  2981 24.0265427281 -0.0265427280742\n",
      "3 massive corr result:  2971 24.2215588489 -0.221558848942\n",
      "4 massive corr result:  2961 24.3548534545 -0.354853454545\n",
      "1 massive corr result:  2990 24.0053686327 -0.00536863274299\n",
      "2 massive corr result:  2980 24.0817960346 -0.0817960345577\n",
      "3 massive corr result:  2970 24.0696749711 -0.0696749711339\n",
      "4 massive corr result:  2960 24.0883160024 -0.0883160023999\n"
     ]
    }
   ],
   "source": [
    "for corr_method in ['fft', 'sad']:\n",
    "    \n",
    "    for y in ['y000','y300','y600','y900','y1200']:\n",
    "        \n",
    "        img_path = ('/home/vytas/1phd/rawdata/bead_experiments/2017-12-15-7um-beads-zscans-static-correct-mirror/'\n",
    "                    + y + '/  Retiga 1350B/')    \n",
    "        imgs = sorted(glob.glob(img_path + \"*.tif\"))\n",
    "        name = '2017-DEC-15th-7um-1024-512-crop-7um-' + y\n",
    "\n",
    "        window_height,window_width = 128, 128\n",
    "        window_big_height, window_big_width = 256,256\n",
    "        # Small IW overlap\n",
    "        overlap_height,overlap_width = 0, 0\n",
    "        #Big IW overlap\n",
    "        overlap_big_height = window_big_height - (window_height - overlap_height)\n",
    "        overlap_big_width = window_big_width - (window_width - overlap_width)\n",
    "        #Centering the IWs\n",
    "        subwindow_inset_height = (window_big_height-window_height)/2\n",
    "        subwindow_inset_width = (window_big_width - window_width)/2\n",
    "\n",
    "\n",
    "        for frame_delta in range(1,5):\n",
    "\n",
    "\n",
    "            #how many frames for 1 um z change\n",
    "            z_step_multiplier = 10\n",
    "            synthetic_px_shift = 24\n",
    "            corr_method =  corr_method#'fft'#'sad' # 'fft'\n",
    "            subpixel_method = 'gaussian'#'gaussian'#'parabolic'\n",
    "\n",
    "            wkdir = ('./corr_avg/' + name + 'frame_delta-' + str(frame_delta) + '-'\n",
    "            + '_' + corr_method + '_' + subpixel_method + '_'\n",
    "            + str(window_height) + '_' + str(window_width) + '_HW_' + str(window_big_height)\n",
    "            + '_' +str(window_big_width) +  '_ol_hw_' + str(overlap_height) + '_'\n",
    "            + str(overlap_width) + '/')\n",
    "            folders = ['xyuvms2n', 'corr', 'metadata']\n",
    "            xyuv_dir,corr_avg_dir,meta_dir = [folder_writer(wkdir, folder) for folder in folders]\n",
    "            ###PARAMS###\n",
    "            data_type = 'int32'\n",
    "\n",
    "            mode =  'valid' # 'full' # \"choose 'full' for same sized windows\"\n",
    "            dt = 1.0\n",
    "            px_size = 1.0 #0.65 # effective (i.e. (true pixel size in camera)/magnification) pixel size in microns\n",
    "            #'gaussian'#'parabolic'\n",
    "            sig2noise_method = 'peak2peak'\n",
    "            threshold = 1.000\n",
    "            width = 3 #half width of the search area/mask around the peak\n",
    "\n",
    "            initial_frame = 0\n",
    "            mean_intensity_thres = 1e5\n",
    "            square = False\n",
    "\n",
    "\n",
    "            path_to_images = img_path\n",
    "            img_files = imgs#sorted( glob.glob( os.path.join( os.path.abspath(path_to_images), '*.tif' ) ) )#[1200:2875]\n",
    "\n",
    "            par_vals = dict( (name,eval(name)) for name in ['window_height','window_width',\n",
    "            'subwindow_inset_height','subwindow_inset_width','overlap_height',\n",
    "            'overlap_width','window_big_height','window_big_width','overlap_big_height',\n",
    "            'overlap_big_width','corr_method','mode','dt','px_size','subpixel_method',\n",
    "            'sig2noise_method','threshold',\n",
    "            'width','frame_delta','initial_frame', 'path_to_images', 'mean_intensity_thres'])\n",
    "\n",
    "            with open(str(wkdir) + '/pars_test.csv', 'wb') as f:\n",
    "                writer = csv.writer(f,delimiter='=')\n",
    "                for row in par_vals.iteritems():\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            ### Should move the below into a seperate file. Just need to work out\n",
    "            ### global variable stuff.\n",
    "            nr_planes = 1\n",
    "            initial_plane = 0\n",
    "\n",
    "            skip_data = None\n",
    "            #shift(imread(images[26*i]), shift = (0,5), mode = 'reflect')\n",
    "            massive_corr = np.zeros((129,129))\n",
    "            massive_corr_single_iws = np.zeros((21,129,129))\n",
    "\n",
    "            for counter, i in enumerate( range(len(img_files)-frame_delta*z_step_multiplier) ):\n",
    "\n",
    "                frame_a = scipy.misc.imread(img_files[i])[0:1024,490:(490+512)].astype(data_type)\n",
    "                #frame_b = scipy.misc.imread(img_files[i+frame_delta]).astype(data_type)\n",
    "\n",
    "                frame_b = shift( scipy.misc.imread(img_files[i+frame_delta*z_step_multiplier])[0:1024,490:(490+512)],\n",
    "                                shift = (0,synthetic_px_shift), mode = 'reflect').astype(data_type)\n",
    "\n",
    "                writer=csv.writer(open(meta_dir + '/frame_pairs.csv', 'a'))\n",
    "                writer.writerow([os.path.basename(img_files[i]), \n",
    "                                 os.path.basename(img_files[i+frame_delta*z_step_multiplier])] )\n",
    "\n",
    "                image_size = frame_a.shape\n",
    "                #size of the \"cropped\" image\n",
    "                image_size_small = (image_size[0] - 2*subwindow_inset_height , image_size[1] - 2*subwindow_inset_width)\n",
    "                #Small IW centres.subwindow_inset_width/height are added to compensate for different sizes in IWs.\n",
    "                x,y = (get_coordinates( image_size_small, window_height, window_width, overlap_height,\n",
    "                                       overlap_width)[0] + subwindow_inset_width,\n",
    "                       get_coordinates( image_size_small, window_height, window_width,\n",
    "                                       overlap_height,overlap_width )[1] + subwindow_inset_height)\n",
    "                #Big IW centres\n",
    "                q,p = (get_coordinates(image_size, window_big_height,window_big_width,\n",
    "                                       overlap_big_height,overlap_big_width)[0],\n",
    "                       get_coordinates(image_size, window_big_height,window_big_width,\n",
    "                                       overlap_big_height,overlap_big_width)[1])\n",
    "                #Check if the IW's have matching centres.\n",
    "                assert(np.array_equal(x, q) == True)\n",
    "                assert(np.array_equal(y, p) == True)\n",
    "                windows_a = moving_sub_window_array(frame_a, window_big_height,window_big_width,\n",
    "                                                    overlap_big_height,overlap_big_width,\n",
    "                                                    subwindow_inset_height,subwindow_inset_width).astype(data_type)\n",
    "\n",
    "                windows_b = moving_window_array( frame_b,window_big_height,window_big_width,\n",
    "                                                overlap_big_height,overlap_big_width).astype(data_type)\n",
    "\n",
    "                corr_shape = correlate_windows( windows_a[0], windows_b[0], corr_method = corr_method, mode = mode).shape\n",
    "                corr = np.zeros((windows_a.shape[0],corr_shape[0],corr_shape[1]))\n",
    "                corr_big_single_iws = np.zeros((windows_a.shape[0],corr_shape[0],corr_shape[1]))\n",
    "                corr_big = np.zeros((1,corr_shape[0],corr_shape[1]))\n",
    "\n",
    "                assert(windows_a.shape[0] == windows_b.shape[0])\n",
    "                n_rows, n_cols = get_field_shape ( frame_a.shape , window_big_height,\n",
    "                                                  window_big_width, overlap_big_height,overlap_big_width )\n",
    "                u = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "                v = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "                sig2noise = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "                intTotIwA = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "                intTotIwB = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "\n",
    "                for j in range(windows_a.shape[0]):\n",
    "                    corr[j] = correlate_windows( windows_a[j], windows_b[j], corr_method = corr_method, mode = mode)\n",
    "                    intTotIwA[j] = np.sum(windows_a[j])\n",
    "                    intTotIwB[j] = np.sum(windows_b[j])\n",
    "                    assert(corr.dtype == np.float64)\n",
    "\n",
    "                corr_big_single_iws = np.add(corr_big_single_iws, corr)\n",
    "                #print \"corr big shape: \", corr_big.shape\n",
    "                #print \"counter: \", counter, \"corr big sum: \", np.sum(corr_big_single_iws)\n",
    "                corr_big = np.sum(corr, axis = 0)\n",
    "                #print \"corr big shape: \", corr_big.shape\n",
    "                #print \"counter: \", counter, \"corr big sum: \", np.sum(corr_big)\n",
    "\n",
    "\n",
    "\n",
    "                if counter%((10*frame_delta + 300))==0:\n",
    "                    #print \"modulo:\", 10*frame_delta + 300\n",
    "                    #print \"adding \", counter, \"nth frame pair corr to the massive corr.\"\n",
    "                    massive_corr = np.add(massive_corr, corr_big)\n",
    "                    massive_corr_single_iws = np.add(massive_corr_single_iws, corr_big_single_iws)\n",
    "                    np.save( corr_avg_dir  + \"/massive_corr_pair_\" + str(\"%04d\" %counter), massive_corr)\n",
    "                    np.save( corr_avg_dir  + \"/massive_corr_SINGLE_IWS_pair_\" + str(\"%04d\" %counter), massive_corr_single_iws)\n",
    "    # ############################################################\n",
    "                    corr_array = massive_corr\n",
    "                    shape_0, shape_1 = 129,129\n",
    "                    figure = plt.figure()\n",
    "                    data = corr_array\n",
    "                    ax = Axes3D(figure)\n",
    "                    nx, ny = shape_0,shape_1\n",
    "                    xx = range(nx)\n",
    "                    yy = range(ny)  \n",
    "                    xmax = np.argmax(np.max(data, axis=0))\n",
    "                    ymax = np.argmax(np.max(data, axis=1))        \n",
    "                    ax.set_xlabel('x axis. Peak column = ' +str(xmax))\n",
    "                    ax.set_ylabel('y axis. Peak row = ' + str(ymax))\n",
    "                    X, Y = np.meshgrid(xx, yy)\n",
    "                    ax.plot_surface(X , Y , data , rstride = 4, cstride = 4,alpha=0.7)\n",
    "                    plt.savefig(wkdir + 'corr_matrix_' + str(counter) + '_fd_' + str(frame_delta) + '.png')\n",
    "                    plt.close()\n",
    "                    figure = plt.figure(figsize = (12,12))\n",
    "                    data = corr_array\n",
    "                    #print \"data shape\", data.shape\n",
    "                    nx, ny = shape_0,shape_1\n",
    "                    xx = range(nx)\n",
    "                    yy = range(ny)  \n",
    "                    xmax = np.argmax(np.max(data, axis=0))\n",
    "                    ymax = np.argmax(np.max(data, axis=1))        \n",
    "                    plt.xlabel('x axis. Peak column = ' +str(xmax))\n",
    "                    plt.ylabel('y axis. Peak row = ' + str(ymax))\n",
    "                    X, Y = np.meshgrid(xx, yy)\n",
    "                    plt.imshow(data, cmap='jet', interpolation='none')\n",
    "                    plt.colorbar()\n",
    "                    plt.contour(data,30,colors='k')\n",
    "                    #plt.xlim(150,300)\n",
    "                    #plt.ylim(100,250)\n",
    "                    #print \"xmax,ymax: \", xmax,ymax\n",
    "                    plt.scatter(xmax,ymax)\n",
    "\n",
    "                    plt.savefig(wkdir + 'corr_heatmap_' + str(counter) + '_fd_' + str(frame_delta) + '.png')\n",
    "                    plt.close()\n",
    "\n",
    "                #np.save( corr_avg_dir  + \"/pair_\" + str(\"%04d\" %counter), corr)\n",
    "\n",
    "                for l in range(corr.shape[0]):#, desc = 'finding subpixel vals for each iw'):\n",
    "                    row, col = find_subpixel_peak_position( corr[l], subpixel_method=subpixel_method,\n",
    "                                                           corr_method = corr_method)\n",
    "                    u[l], v[l] = px_size*(col - corr_shape[1]/2), -px_size*(row - corr_shape[0]/2)\n",
    "                    sig2noise[l] = sig2noise_ratio( corr[l], sig2noise_method=sig2noise_method,\n",
    "                                                   corr_method= corr_method, width=width, square=square)\n",
    "\n",
    "                u,v,sig2noise = u.reshape(n_rows, n_cols), v.reshape(n_rows, n_cols),sig2noise.reshape(n_rows, n_cols)\n",
    "                u,v, mask = sig2noise_val( u, v, sig2noise, threshold)\n",
    "                #print counter, u[0][0], synthetic_px_shift - u[0][0],\n",
    "\n",
    "                #writer=csv.writer(open(meta_dir + '/du.csv', 'a'))\n",
    "                #writer.writerow([synthetic_px_shift - u[0][0]] )\n",
    "\n",
    "                xyuvms2n_single = xyuv_dir + \"/xyuvms2n_pair_single_pairs_no_corr_av_\" + str(\"%06d\" %counter) + \".txt\"\n",
    "                #save( x, y, u, v, mask, sig2noise, xyuvms2n_single, fmt='%8.4f', delimiter='\\t' )\n",
    "                saveWithInt( x, y, u, v, mask, sig2noise,intTotIwA,intTotIwB, xyuvms2n_single, fmt='%8.4f', delimiter='\\t')\n",
    "\n",
    "\n",
    "                ###########corr big#########\n",
    "\n",
    "                row, col = find_subpixel_peak_position( corr_big, subpixel_method=subpixel_method,\n",
    "                                                           corr_method = corr_method)\n",
    "                u_ca, v_ca = px_size*(col - corr_shape[1]/2), -px_size*(row - corr_shape[0]/2)\n",
    "\n",
    "                #print \"corr av result: \", counter, u, synthetic_px_shift - u\n",
    "\n",
    "                writer=csv.writer(open(meta_dir + '/du_ca.csv', 'a'))\n",
    "                writer.writerow([np.abs(synthetic_px_shift - u_ca)] )\n",
    "\n",
    "\n",
    "            ########################massive corr single iws##############\n",
    "            u = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "            v = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "            sig2noise = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "            intTotIwA = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "            intTotIwB = np.zeros(n_rows*n_cols).astype(np.float64)\n",
    "            for l in range(massive_corr_single_iws.shape[0]):\n",
    "                #print \"massive_corr_single_iws.shape[0]\", massive_corr_single_iws.shape[0]\n",
    "                row, col = find_subpixel_peak_position( massive_corr_single_iws[l], subpixel_method=subpixel_method,\n",
    "                                                       corr_method = corr_method)\n",
    "                #print row,col\n",
    "                u[l], v[l] = px_size*(col - corr_shape[1]/2), -px_size*(row - corr_shape[0]/2)\n",
    "                sig2noise[l] = sig2noise_ratio( corr[l], sig2noise_method=sig2noise_method,\n",
    "                                               corr_method= corr_method, width=width, square=square)\n",
    "\n",
    "            u,v,sig2noise = u.reshape(n_rows, n_cols), v.reshape(n_rows, n_cols),sig2noise.reshape(n_rows, n_cols)\n",
    "            u,v, mask = sig2noise_val( u, v, sig2noise, threshold)\n",
    "            xyuvms2n_single_iw_ca = xyuv_dir + \"/single_iw_CAV_xyuvms2n\" + \".txt\"\n",
    "            saveWithInt( x, y, u, v, mask, sig2noise,intTotIwA,intTotIwB, xyuvms2n_single_iw_ca, fmt='%8.4f', delimiter='\\t')\n",
    "            writer=csv.writer(open(meta_dir + '/du_massive_corr_single_iw_frame_delta_' + str(frame_delta) + '.csv', 'a'))\n",
    "            for row in u:\n",
    "                for val in row:\n",
    "                    writer.writerow([val, np.abs(synthetic_px_shift - val)])\n",
    "\n",
    "\n",
    "\n",
    "            ###########################massive corr#####################\n",
    "            row, col = find_subpixel_peak_position( massive_corr, subpixel_method=subpixel_method,\n",
    "                                                       corr_method = corr_method)\n",
    "\n",
    "            u_ca_mass, v_ca_mass = px_size*(col - corr_shape[1]/2), -px_size*(row - corr_shape[0]/2)\n",
    "            #print u_ca_mass\n",
    "            writer=csv.writer(open(meta_dir + '/du_massive_corr.csv', 'a'))\n",
    "            writer.writerow([synthetic_px_shift - u_ca_mass,np.abs(synthetic_px_shift - u_ca_mass)] )\n",
    "\n",
    "            print frame_delta, \"massive corr result: \", counter, u_ca_mass, synthetic_px_shift - u_ca_mass\n",
    "            np.save( corr_avg_dir  + \"/frame_delta_massive_corr_\" + str(\"%03d\" %frame_delta), massive_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 massive corr result:  2989 24.0355591278 -0.0355591277624\n",
    "\n",
    "#corrs = sorted(glob.glob( os.path.join( os.path.abspath(corr_avg_dir), '*.npy' ) ))\n",
    "#corr_array = np.load(corrs[0])\n",
    "corr_array = massive_corr\n",
    "#shape_0,shape_1 =corr_array.shape[2], corr_array.shape[1]\n",
    "shape_0,shape_1 =corr_array.shape[1], corr_array.shape[0]\n",
    "#for single_corr in corrs[1:]:\n",
    " #   corr_array = np.add(corr_array, np.load(single_corr))\n",
    "    #print(\"{:.2e}\".format(np.amin(corr_array)),(\"{:.2e}\".format(np.amax(corr_array)))) \n",
    "#massive_corr = np.load('/home/vytas/1repo_clones/padded_piv/corr_avg/dec-12-up-to-20um/piv_results/Dec12th-11-15-01-7um-beads-CROP-512-1_fft_gaussian_128_128_HW_256_256_ol_hw_0_0/corr/frame_delta_massive_corr_001.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print u[0][0],v[0][0]\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_array = massive_corr\n",
    "shape_0, shape_1 = 129,129\n",
    "figure = plt.figure()\n",
    "data = corr_array\n",
    "ax = Axes3D(figure)\n",
    "nx, ny = shape_0,shape_1\n",
    "xx = range(nx)\n",
    "yy = range(ny)  \n",
    "xmax = np.argmax(np.max(data, axis=0))\n",
    "ymax = np.argmax(np.max(data, axis=1))        \n",
    "ax.set_xlabel('x axis. Peak column = ' +str(xmax))\n",
    "ax.set_ylabel('y axis. Peak row = ' + str(ymax))\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "ax.plot_surface(X , Y , data , rstride = 4, cstride = 4,alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize = (24,24))\n",
    "data = corr_array\n",
    "print \"data shape\", data.shape\n",
    "nx, ny = shape_0,shape_1\n",
    "xx = range(nx)\n",
    "yy = range(ny)  \n",
    "xmax = np.argmax(np.max(data, axis=0))\n",
    "ymax = np.argmax(np.max(data, axis=1))        \n",
    "plt.xlabel('x axis. Peak column = ' +str(xmax))\n",
    "plt.ylabel('y axis. Peak row = ' + str(ymax))\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "plt.imshow(data, cmap='jet', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.contour(data,30,colors='k')\n",
    "#plt.xlim(150,300)\n",
    "#plt.ylim(100,250)\n",
    "\n",
    "plt.scatter(xmax,ymax)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
